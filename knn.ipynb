{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_digits\n",
    "data = load_boston()\n",
    "#data = load_digits()\n",
    "datas = data['data']\n",
    "targets = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50.0, 16), (25.0, 8), (21.7, 7), (23.1, 7), (22.0, 7)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test my_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/algorithms/machine_learning/kn_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "%run kn_classifier.py\n",
    "from model_selection import train_test_split\n",
    "from metrics import accuracy_score\n",
    "from preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = datas.shape[0]\n",
    "loops = 20\n",
    "test_ratio = 0.2\n",
    "my_knn = KNclassifier(5,weights='uniform')\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy of knn:  0.02970297029702971\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in np.arange(loops):\n",
    "    \n",
    "    train_x ,test_x,train_y,test_y = train_test_split(datas,targets,test_ratio=test_ratio,seed=66)\n",
    "    ss.fit(train_x)\n",
    "    s_train_x = ss.transform(train_x)\n",
    "    s_test_x= ss.transform(test_x)\n",
    "    \n",
    "    my_knn.fit(s_train_x,train_y)\n",
    "    #predictions = my_knn.predict(test_x)\n",
    "\n",
    "    accuracy = my_knn.score(s_test_x,test_y)\n",
    "    results.append(accuracy)\n",
    "\n",
    "print('average accuracy of knn: ', np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable           Type              Data/Info\n",
      "----------------------------------------------\n",
      "Counter            type              <class 'collections.Counter'>\n",
      "KNclassifier       type              <class '__main__.KNclassifier'>\n",
      "StandardScaler     type              <class 'preprocessing.StandardScaler'>\n",
      "accuracy           float64           0.0297029702970297\n",
      "accuracy_score     function          <function accuracy_score at 0x1157b75f0>\n",
      "counts             int               506\n",
      "data               Bunch             {'data': array([[6.3200e-<...>boston_house_prices.csv'}\n",
      "datas              ndarray           506x13: 6578 elems, type `float64`, 52624 bytes\n",
      "knn                function          <function knn at 0x115818950>\n",
      "load_boston        function          <function load_boston at 0x1145cc290>\n",
      "load_digits        function          <function load_digits at 0x1145cc0e0>\n",
      "loops              int               20\n",
      "my_knn             KNclassifier      <__main__.KNclassifier object at 0x1157c5b90>\n",
      "np                 module            <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "r2_score           function          <function r2_score at 0x1157b7dd0>\n",
      "results            list              n=20\n",
      "s_test_x           ndarray           101x13: 1313 elems, type `float64`, 10504 bytes\n",
      "s_train_x          ndarray           405x13: 5265 elems, type `float64`, 42120 bytes\n",
      "ss                 StandardScaler    <preprocessing.StandardSc<...>er object at 0x1157c5c10>\n",
      "targets            ndarray           506: 506 elems, type `float64`, 4048 bytes\n",
      "test_ratio         float             0.2\n",
      "test_x             ndarray           101x13: 1313 elems, type `float64`, 10504 bytes\n",
      "test_y             ndarray           101: 101 elems, type `float64`, 808 bytes\n",
      "train_test_split   function          <function train_test_split at 0x1157b7950>\n",
      "train_x            ndarray           405x13: 5265 elems, type `float64`, 42120 bytes\n",
      "train_y            ndarray           405: 405 elems, type `float64`, 3240 bytes\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test myknn_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kn_regressor.py\n",
    "from model_selection import train_test_split\n",
    "from metrics import r2_score\n",
    "from preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = datas.shape[0]\n",
    "loops = 20\n",
    "test_ratio = 0.2\n",
    "my_knn = KNRegressor(5,weights='distance')\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of knn:  0.8129891209408775\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in np.arange(loops):\n",
    "    \n",
    "    train_x ,test_x,train_y,test_y = train_test_split(datas,targets,test_ratio=test_ratio)\n",
    "    ss.fit(train_x)\n",
    "    s_train_x = ss.transform(train_x)\n",
    "    s_test_x= ss.transform(test_x)\n",
    "    \n",
    "    my_knn.fit(s_train_x,train_y)\n",
    "    #predictions = my_knn.predict(test_x)\n",
    "\n",
    "    #accuracy = accuracy_score(test_y,predictions)\n",
    "    accuracy = my_knn.score(s_test_x,test_y)\n",
    "    results.append(accuracy)\n",
    "\n",
    "print('average error of knn: ', np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test my linear_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run linear_regressor.py\n",
    "from model_selection import train_test_split\n",
    "from metrics import r2_score\n",
    "from preprocessing import StandardScaler\n",
    "\n",
    "loops = 10\n",
    "test_ratio = 0.2\n",
    "my_linear_reg = LinearRegressor()\n",
    "ss = StandardScaler()\n",
    "\n",
    "datas = datas[targets<50]\n",
    "targets = targets[targets<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of linear regressor:  0.7449601405805827\n"
     ]
    }
   ],
   "source": [
    "results =[]\n",
    "for _ in np.arange(loops):\n",
    "    \n",
    "    train_x ,test_x,train_y,test_y = train_test_split(datas,targets,test_ratio=test_ratio)\n",
    "    ss.fit(train_x)\n",
    "    s_train_x = ss.transform(train_x)\n",
    "    s_test_x = ss.transform(test_x)\n",
    "    my_linear_reg.fit_gd(s_train_x,train_y)\n",
    "    #my_linear_reg.fit_normal(s_train_x,train_y)\n",
    "    errors = my_linear_reg.score(s_test_x,test_y)\n",
    "    results.append(errors)\n",
    "\n",
    "print('average error of linear regressor: ', np.mean(results))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 2.],\n",
       "       [1., 3.],\n",
       "       [1., 4.],\n",
       "       [1., 5.],\n",
       "       [1., 6.],\n",
       "       [1., 7.],\n",
       "       [1., 8.],\n",
       "       [1., 9.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([np.ones((10,1)),np.arange(10).reshape(10,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<preprocessing.StandardScaler at 0x120db8bd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linear_reg.fit(ss.transform(datas),targets)\n",
    "coef1 = my_linear_reg.coef_\n",
    "my_linear_reg.fit(datas,targets)\n",
    "coef2 = my_linear_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inx = np.argsort(np.abs(coef1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inx = inx[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5,  7, 10, 12,  3,  8,  0,  2,  1,  6,  9, 11])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['NOX', 'RM', 'DIS', 'PTRATIO', 'LSTAT'], dtype='<U7'),\n",
       " array([-1.,  1., -1., -1., -1.]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names[inx[:5]],np.sign(coef1[inx[:5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'weights':['uniform'],'n_neighbors':[i for i in np.arange(3,11)]},{'weights':['distance'],'n_neighbors':[i for i in np.arange(3,11)],'p':[i for i in np.arange(1,5)]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights': ['uniform'], 'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10]},\n",
       " {'weights': ['distance'],\n",
       "  'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10],\n",
       "  'p': [1, 2, 3, 4]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_search = GridSearchCV(knn_classifier,params,n_jobs=-1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    8.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 377 ms, sys: 78.9 ms, total: 456 ms\n",
      "Wall time: 57.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   57.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'weights': ['uniform'], 'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10]}, {'weights': ['distance'], 'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10], 'p': [1, 2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "grid_search.fit(datas,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682804674457429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
